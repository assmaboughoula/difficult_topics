1
00:00:00,025 --> 00:00:06,458
[SOUND] This lecture is about the feedback

2
00:00:06,458 --> 00:00:12,330
in the language modeling approach.

3
00:00:12,330 --> 00:00:17,520
In this lecture we will continue the
discussion of feedback in text retrieval.

4
00:00:17,520 --> 00:00:20,800
In particular we're going to talk about
the feedback in language modeling

5
00:00:20,800 --> 00:00:21,360
approaches.

6
00:00:23,450 --> 00:00:29,280
So we derive the query likelihood ranking
function by making various assumptions.

7
00:00:30,410 --> 00:00:35,860
As a basic retrieval function, that
formula, or those formulas worked well.

8
00:00:35,860 --> 00:00:39,910
But if we think about the feedback
information, it's a little bit awkward to

9
00:00:39,910 --> 00:00:44,730
use query likelihood to
perform feedback because

10
00:00:44,730 --> 00:00:49,620
a lot of times the feedback information is
additional information about the query.

11
00:00:49,620 --> 00:00:53,260
But we assume the query is
generated by assembling words

12
00:00:53,260 --> 00:00:56,850
from a language model in
the query likelihood method.

13
00:00:56,850 --> 00:01:03,170
It's kind of unnatural to sample,
words that, form feedback documents.

14
00:01:03,170 --> 00:01:06,460
As a result, then research is proposed,

15
00:01:06,460 --> 00:01:10,360
a way to generalize query
likelihood function.

16
00:01:10,360 --> 00:01:14,060
It's called a Kullback-Leibler
divergence retrieval model.

17
00:01:15,450 --> 00:01:20,960
And this model is actually,
going to make the query likelihood,

18
00:01:20,960 --> 00:01:25,780
our retrieval function much
closer to vector space model.

19
00:01:25,780 --> 00:01:32,660
Yet this, form of the language model can
be, regarded as a generalization of query

20
00:01:32,660 --> 00:01:36,600
likelihood in the sense that if it can
cover query likelihood as a special case.

21
00:01:38,180 --> 00:01:41,820
And in this case the feedback
can be achieved through

22
00:01:41,820 --> 00:01:44,180
simply query model estimation or updating.

23
00:01:44,180 --> 00:01:48,120
This is very similar to Rocchio
which updates the query vector.

24
00:01:50,000 --> 00:01:55,022
So let's see what the, is the scale
of divergence, which we will model.

25
00:01:55,022 --> 00:01:59,529
So, on the top, what you see is query

26
00:01:59,529 --> 00:02:05,087
likelihood retrieval function,
all right, this one.

27
00:02:05,087 --> 00:02:11,417
And then KL-divergence or
also called cross entropy retrieval

28
00:02:11,417 --> 00:02:16,808
model is basically to
generalize the frequency part,

29
00:02:16,808 --> 00:02:21,150
here, into a layered model.

30
00:02:21,150 --> 00:02:24,975
So basically it's the difference,

31
00:02:24,975 --> 00:02:29,910
given by the probabilistic model here

32
00:02:29,910 --> 00:02:34,640
to characterize what the user's looking
for versus the kind of query words there.

33
00:02:35,810 --> 00:02:42,610
And this difference allows us to plotting
various different ways to estimate this.

34
00:02:42,610 --> 00:02:48,270
So this can be estimated in many different
ways including using feedback information.

35
00:02:48,270 --> 00:02:51,410
Now this is called a KL-divergence because

36
00:02:51,410 --> 00:02:56,231
this can be interpreted as measuring
the KL-divergence of two distributions.

37
00:02:56,231 --> 00:03:02,935
One is the query model
denoted by this distribution.

38
00:03:02,935 --> 00:03:07,380
One is the talking,
the language model here.

39
00:03:07,380 --> 00:03:11,605
And [INAUDIBLE] though is a [INAUDIBLE]
language model, of course.

40
00:03:11,605 --> 00:03:15,647
And we are not going to talk
about the detail of that, and

41
00:03:15,647 --> 00:03:18,361
you'll find the things in references.

42
00:03:18,361 --> 00:03:22,769
It's also called cross entropy,
because, in, in fact,

43
00:03:22,769 --> 00:03:27,407
we can ignore some terms in the
KL-divergence function and we will end up

44
00:03:27,407 --> 00:03:32,750
having actually cross entropy, and that,
both are terms in information theory.

45
00:03:34,410 --> 00:03:35,330
But, anyway for

46
00:03:36,970 --> 00:03:42,820
our purposes here you can just see
the two formulas look almost identical,

47
00:03:42,820 --> 00:03:48,220
except that here we have a probability of
a word given by a query language model.

48
00:03:49,440 --> 00:03:52,590
This, and here,

49
00:03:52,590 --> 00:03:57,480
the sum is over all the words
that are in the document,

50
00:03:57,480 --> 00:04:02,340
and also with the non-zero probability for
the query model.

51
00:04:02,340 --> 00:04:07,510
So it's kind of, again, a generalization
of sum over all the matching query words.

52
00:04:09,940 --> 00:04:14,470
Now you can also, easy to see,
we can recover the query likelihood,

53
00:04:14,470 --> 00:04:18,450
which we will find here by as simple
as setting this query model to

54
00:04:18,450 --> 00:04:23,440
the relative frequency of
a word in the query, right?

55
00:04:23,440 --> 00:04:25,950
This is very to easy see
once you practice this.

56
00:04:25,950 --> 00:04:29,940
And to here, you can eliminate this
query lens, that's a constant,

57
00:04:29,940 --> 00:04:32,410
and then you get exactly like that.

58
00:04:33,830 --> 00:04:36,200
So you can see the equivalence.

59
00:04:36,200 --> 00:04:41,840
And that's also why this KL-divergence
model can be regarded as a generalization

60
00:04:41,840 --> 00:04:47,480
of query likelihood because we can cover
query likelihood as a special case,

61
00:04:47,480 --> 00:04:49,469
but it would also allow it
to do much more than that.

62
00:04:50,760 --> 00:04:56,350
So this is how we use the KL-divergence
model to then do feedback.

63
00:04:56,350 --> 00:05:00,480
The picture shows that we first
estimate a document language model,

64
00:05:00,480 --> 00:05:02,840
then we estimate a query
language model and

65
00:05:02,840 --> 00:05:07,060
we compute the KL-divergence,
this is often denoted by a D here.

66
00:05:09,540 --> 00:05:14,290
But this basically means,
this was exactly like in vector space

67
00:05:14,290 --> 00:05:18,280
model because we compute the vector for
the document in the computer and

68
00:05:18,280 --> 00:05:22,440
not the vector for the query,
and then we compute the distance.

69
00:05:22,440 --> 00:05:25,050
Only that these vectors
are of special forms,

70
00:05:25,050 --> 00:05:26,580
they have probability distributions.

71
00:05:27,950 --> 00:05:31,680
And then we get the results, and
we can find some feedback documents.

72
00:05:31,680 --> 00:05:37,420
Let's assume they are more selective
sorry, mostly positive documents.

73
00:05:37,420 --> 00:05:40,400
Although we could also consider
both kinds of documents.

74
00:05:40,400 --> 00:05:42,881
So what we could do is, like in Rocchio,

75
00:05:42,881 --> 00:05:48,570
we can compute another language model
called feedback language model here.

76
00:05:48,570 --> 00:05:52,992
Again, this is going to be another vector
just like a computing centroid vector in

77
00:05:52,992 --> 00:05:53,592
Rocchio.

78
00:05:53,592 --> 00:05:56,472
And then this model can be
combined with the original

79
00:05:56,472 --> 00:05:58,899
query model using a linear interpolation.

80
00:06:00,490 --> 00:06:04,630
And this would then give us an updated
model, just like again in Rocchio.

81
00:06:05,810 --> 00:06:10,676
Right, so here, we can see the parameter
of our controlling amount of feedback if

82
00:06:10,676 --> 00:06:14,075
it's set to 0,
then it says here there's no feedback.

83
00:06:14,075 --> 00:06:19,050
After set to 1, we've got full feedback,
we can ignore the original query.

84
00:06:19,050 --> 00:06:21,820
And this is generally not desirable,
right.

85
00:06:21,820 --> 00:06:27,640
So this unless you are absolutely sure you
have seen a lot of relevant documents and

86
00:06:27,640 --> 00:06:29,290
the query terms are not important.

87
00:06:31,180 --> 00:06:34,870
So of course the main question here
is how do you compute this theta F?

88
00:06:34,870 --> 00:06:36,790
This is the big question here.

89
00:06:36,790 --> 00:06:39,340
And once you can do that,
the rest is easy.

90
00:06:39,340 --> 00:06:41,640
So here we'll talk about
one of the approaches.

91
00:06:41,640 --> 00:06:43,270
And there are many approaches of course.

92
00:06:43,270 --> 00:06:48,050
This approach is based on generative model
and I'm going to show you how it works.

93
00:06:48,050 --> 00:06:50,550
This is a user generative mixture model.

94
00:06:50,550 --> 00:06:55,030
So this picture shows that
the we have this model here,

95
00:06:55,030 --> 00:06:58,080
the feedback model that
we want to estimate.

96
00:06:58,080 --> 00:07:00,490
And we the basis is the feedback options.

97
00:07:00,490 --> 00:07:04,110
Let's say we are observing
the positive documents.

98
00:07:04,110 --> 00:07:08,540
These are the collected documents by
users, or random documents judged by

99
00:07:08,540 --> 00:07:12,670
users, or simply top ranked documents
that we assumed to be random.

100
00:07:14,710 --> 00:07:17,360
Now imagine how we can
compute a centroid for

101
00:07:17,360 --> 00:07:20,630
these documents by using language model.

102
00:07:20,630 --> 00:07:23,330
One approach is simply to assume

103
00:07:23,330 --> 00:07:28,210
these documents are generated from
this language model as we did before.

104
00:07:28,210 --> 00:07:32,120
What we could do is do it,
just normalize the word frequency here.

105
00:07:32,120 --> 00:07:34,940
And then we,
we'll get this word distribution.

106
00:07:36,210 --> 00:07:39,870
Now the question is whether this
distribution is good for feedback.

107
00:07:39,870 --> 00:07:44,610
Well you can imagine well the top
rank of the words would be what?

108
00:07:45,700 --> 00:07:46,200
What do you think?

109
00:07:48,280 --> 00:07:51,241
Well those words would be common words,
right?

110
00:07:51,241 --> 00:07:53,680
As well we see in, in the language model,

111
00:07:53,680 --> 00:07:57,850
in the top right, the words are actually
common words like, the, et cetera.

112
00:07:57,850 --> 00:08:02,610
So, it's not very good for feedback,
because we will be adding a lot of such

113
00:08:02,610 --> 00:08:07,350
words to our query when we interpret,
this was the original query model.

114
00:08:08,870 --> 00:08:13,690
So, this is not good, so
we need to do something, in particular,

115
00:08:13,690 --> 00:08:17,330
we are trying to get rid
of those common words.

116
00:08:17,330 --> 00:08:21,230
And we all, we have seen actually one way
to do that, by using background language

117
00:08:21,230 --> 00:08:27,470
model in the case of learning
the associations with of words, right.

118
00:08:27,470 --> 00:08:29,610
The words that are related
to the word computer.

119
00:08:30,830 --> 00:08:33,620
We could do that, and
that would be another way to do this.

120
00:08:33,620 --> 00:08:36,290
But here, we're going to
talk about another approach,

121
00:08:36,290 --> 00:08:39,160
which is a more principled approach.

122
00:08:39,160 --> 00:08:43,470
In this case, we're going to say, well,
you, you said that there are common words

123
00:08:43,470 --> 00:08:49,300
here in this, these documents that should
not belong to this top model, right?

124
00:08:50,310 --> 00:08:54,990
So now, what we can do is to assume that,
well, those words are, generally,

125
00:08:54,990 --> 00:08:58,020
from background language model,
so they will generate a,

126
00:08:58,020 --> 00:09:01,260
those words like the, for example.

127
00:09:02,430 --> 00:09:05,079
And if we use maximum
likelihood estimated,

128
00:09:05,079 --> 00:09:11,300
note that if all the words here
must be generated from this model,

129
00:09:11,300 --> 00:09:16,830
then this model is forced to assign
high probabilities to a word like the,

130
00:09:16,830 --> 00:09:19,700
because it occurs so frequently here.

131
00:09:19,700 --> 00:09:24,800
Note that in order to reduce its
probability in this model, we have to

132
00:09:24,800 --> 00:09:31,280
have another model, which is this one
to help explain the word, the, here.

133
00:09:31,280 --> 00:09:32,860
And in this case,

134
00:09:32,860 --> 00:09:37,550
it's not appropriate to use the background
language model to achieve this goal

135
00:09:37,550 --> 00:09:42,310
because this model will assign high
probabilities to these common words.

136
00:09:43,370 --> 00:09:46,740
So in this approach then, we assume

137
00:09:46,740 --> 00:09:50,810
this machine that which generated
these words would work as follows.

138
00:09:50,810 --> 00:09:53,620
We have a source controller here.

139
00:09:53,620 --> 00:09:59,100
Imagine we flip a coin here to
decide what distribution to use.

140
00:09:59,100 --> 00:10:02,250
With the probability of lambda
the coin shows up as head.

141
00:10:02,250 --> 00:10:05,390
And then we're going to use
the background language model.

142
00:10:05,390 --> 00:10:08,540
And we can do then sample
word from that model.

143
00:10:08,540 --> 00:10:11,522
With probability of 1 minus lambda now,

144
00:10:11,522 --> 00:10:17,440
we now decide to use a unknown topic
model here that we will try to estimate.

145
00:10:17,440 --> 00:10:20,100
And we're going to then
generate a word here.

146
00:10:20,100 --> 00:10:25,060
If we make this assumption, and this
whole thing will be just one model, and

147
00:10:25,060 --> 00:10:27,180
we call this a mixture model,

148
00:10:27,180 --> 00:10:30,400
because there are two distributions
that are mixed here together.

149
00:10:30,400 --> 00:10:33,940
And we actually don't know when
each distribution is used.

150
00:10:35,150 --> 00:10:40,050
Right, so again think of this
whole thing as one model.

151
00:10:40,050 --> 00:10:42,904
And we can still ask it for words, and

152
00:10:42,904 --> 00:10:47,910
it will still give us a word
in a random method, right?

153
00:10:47,910 --> 00:10:52,000
And of course which word will show up
will depend on both this distribution and

154
00:10:52,000 --> 00:10:53,295
that distribution.

155
00:10:53,295 --> 00:10:56,200
In addition,
it would also depend on this lambda,

156
00:10:56,200 --> 00:10:58,970
because if you say,
lambda is very high and

157
00:10:58,970 --> 00:11:02,920
it's going to always use the background
distribution, you'll get different words.

158
00:11:02,920 --> 00:11:07,244
If you say, well our lambda is very small,
we're going to use this, all right?

159
00:11:07,244 --> 00:11:12,562
So all these are parameters,
in this model.

160
00:11:12,562 --> 00:11:15,189
And then, if you're thinking this way,

161
00:11:15,189 --> 00:11:20,068
basically we can do exactly the same as
what we did before, we're going to use

162
00:11:20,068 --> 00:11:25,760
maximum likelihood estimator to adjust
this model to estimate the parameters.

163
00:11:25,760 --> 00:11:30,580
Basically we're going to adjust,
well, this parameter so

164
00:11:30,580 --> 00:11:32,900
that we can best explain all the data.

165
00:11:32,900 --> 00:11:41,200
The difference now is that we are not
asking this model alone to explain this.

166
00:11:41,200 --> 00:11:45,540
But rather we're going to ask
this whole model, mixture model,

167
00:11:45,540 --> 00:11:50,530
to explain the data because it has got
some help from the background model.

168
00:11:50,530 --> 00:11:54,080
It doesn't have to assign high
probabilities towards like the,

169
00:11:54,080 --> 00:11:55,150
as a result.

170
00:11:55,150 --> 00:12:01,136
It would then assign high probabilities
to other words that are common here but

171
00:12:01,136 --> 00:12:04,950
not having high probability here.

172
00:12:04,950 --> 00:12:07,063
So those would be common here.

173
00:12:10,093 --> 00:12:11,393
Right?

174
00:12:11,393 --> 00:12:15,069
And if they're common they would
have to have high probabilities,

175
00:12:15,069 --> 00:12:17,658
according to a maximum
likelihood estimator.

176
00:12:17,658 --> 00:12:23,512
And if they are rare here,
all right, so if they are rare here,

177
00:12:23,512 --> 00:12:29,620
then you don't get much help
from this background model.

178
00:12:29,620 --> 00:12:33,940
As a result, this topic model
must assign high probabilities.

179
00:12:33,940 --> 00:12:37,370
So the higher probability words
according to the topic model

180
00:12:37,370 --> 00:12:41,710
will be those that are common here,
but rare in the background.

181
00:12:43,370 --> 00:12:49,520
Okay, so, this is basically a little
bit like a idea for weighting here.

182
00:12:49,520 --> 00:12:53,800
This would allow us to achieve
the effect of removing these top words

183
00:12:53,800 --> 00:12:56,790
that are meaningless in the feedback.

184
00:12:56,790 --> 00:13:01,553
So mathematically what we have is
to compute the likelihood again,

185
00:13:01,553 --> 00:13:05,150
local likelihood of
the feedback documents.

186
00:13:05,150 --> 00:13:08,720
And, and note that, we also have
another parameter, lambda here.

187
00:13:08,720 --> 00:13:13,150
But we assume that lambda denotes
noise in the feedback document.

188
00:13:13,150 --> 00:13:16,510
So we are going to, let's say,
set this to a parameter, let's say,

189
00:13:16,510 --> 00:13:21,800
say 50% of the words are noise,
or 90% are noise.

190
00:13:21,800 --> 00:13:24,600
And this can then be,
assume it will be fixed.

191
00:13:24,600 --> 00:13:31,081
If we assume this is fixed, then we only
have these probabilities as parameters

192
00:13:31,081 --> 00:13:37,120
just like in the simplest unigram
language model, we have n parameters.

193
00:13:37,120 --> 00:13:41,289
n is the number of words and, then, the
likelihood function will look like this.

194
00:13:42,760 --> 00:13:46,610
It's very similar to the likelihood
function, normal likelihood

195
00:13:46,610 --> 00:13:52,100
function we see before except that inside
the logarithm there's a sum in here.

196
00:13:52,100 --> 00:13:57,070
And this sum is because we can
see the two distributions.

197
00:13:57,070 --> 00:14:01,300
And which ones used would depend on
lambda and that's why we have this form.

198
00:14:02,460 --> 00:14:08,790
But mathematically this is the function
with theta as unknown variables, right?

199
00:14:08,790 --> 00:14:10,510
So, this is just a function.

200
00:14:10,510 --> 00:14:13,910
All the other variables are known,
except for this guy.

201
00:14:15,000 --> 00:14:19,658
So, we can then choose this
probability distribution to

202
00:14:19,658 --> 00:14:22,287
maximize this log likelihood.

203
00:14:22,287 --> 00:14:25,030
The same idea as the maximum
likelihood estimator.

204
00:14:25,030 --> 00:14:27,304
As a mathematical problem which is to,

205
00:14:27,304 --> 00:14:30,060
we just have to solve this
optimization problem.

206
00:14:30,060 --> 00:14:33,048
We said we would try all
of the theta values, and

207
00:14:33,048 --> 00:14:37,471
here we find one that gives this
whole thing the maximum probability.

208
00:14:37,471 --> 00:14:40,682
So, it's a well-defined math problem.

209
00:14:40,682 --> 00:14:43,490
Once we have done that,
we obtain this theta F,

210
00:14:43,490 --> 00:14:47,860
that can be the interpreter with
the original query model to do feedback.

211
00:14:50,990 --> 00:14:56,020
So here are some examples of
the feedback model learned from a web

212
00:14:56,020 --> 00:14:59,510
document collection, and
we do pseudo-feedback.

213
00:14:59,510 --> 00:15:03,760
We just use the top 10 documents,
and we use this mixture model.

214
00:15:03,760 --> 00:15:06,090
So the query is airport security.

215
00:15:06,090 --> 00:15:11,360
What we do is we first retrieve ten
documents from the web database.

216
00:15:11,360 --> 00:15:13,929
And this is of course pseudo-feedback,
right?

217
00:15:13,929 --> 00:15:20,872
And then we're going to feed to that
mixture model, to this ten document set.

218
00:15:20,872 --> 00:15:25,500
And these are the words
learned using this approach.

219
00:15:25,500 --> 00:15:30,220
This is the probability of a word given
by the feedback model in both cases.

220
00:15:31,600 --> 00:15:35,700
So, in both cases, you can see
the highest probability of words

221
00:15:35,700 --> 00:15:38,480
include very random words to the query.

222
00:15:38,480 --> 00:15:40,200
So, airport security for example,

223
00:15:40,200 --> 00:15:43,740
these query words still show
up as high probabilities

224
00:15:43,740 --> 00:15:48,850
in each case naturally because they occur
frequently in the top rank of documents.

225
00:15:48,850 --> 00:15:53,500
But we also see beverage, alcohol,
bomb, terrorist, et cetera.

226
00:15:53,500 --> 00:15:58,920
Right, so these are relevant
to this topic, and they,

227
00:15:58,920 --> 00:16:05,280
if combined with original query can help
us match more accurately, on documents.

228
00:16:05,280 --> 00:16:10,700
And also they can help us bring up
documents that only managing the,

229
00:16:10,700 --> 00:16:12,710
some of these other words.

230
00:16:12,710 --> 00:16:17,780
And maybe for example just airport and
then bomb for example.

231
00:16:17,780 --> 00:16:20,680
These so,
this is how pseudo-feedback works.

232
00:16:20,680 --> 00:16:22,930
It shows that this model really works and

233
00:16:22,930 --> 00:16:26,790
picks up mm,
some related words to the query.

234
00:16:26,790 --> 00:16:31,320
What's also interesting is that if
you look at the two tables here, and

235
00:16:31,320 --> 00:16:36,050
you compare them, and you see in this
case, when lambda is set to a small value,

236
00:16:36,050 --> 00:16:41,773
and we'll still see some common
words here, and that means.

237
00:16:41,773 --> 00:16:45,732
When we don't use the background
model often, remember lambda can

238
00:16:45,732 --> 00:16:50,955
use the probability of using the
background model to generate to the text.

239
00:16:50,955 --> 00:16:53,245
If we don't rely much on background model,

240
00:16:53,245 --> 00:16:58,100
we still have to use this topped model
to account for the common words.

241
00:16:58,100 --> 00:17:03,062
Whereas if we set lambda to a very
high value we would use the background

242
00:17:03,062 --> 00:17:06,980
model very often to explain these words,
then there is no burden on

243
00:17:06,980 --> 00:17:11,800
expanding those common words in the
feedback documents by the topping model.

244
00:17:11,800 --> 00:17:17,400
So, as a result, the top of the model
here is very discriminative.

245
00:17:17,400 --> 00:17:20,070
It contains all the relevant
words without common words.

246
00:17:21,200 --> 00:17:26,100
So this can be added to the original
query to achieve feedback.

247
00:17:28,180 --> 00:17:32,300
So to summarize in this lecture we
have talked about the feedback in

248
00:17:32,300 --> 00:17:34,390
language model approach.

249
00:17:34,390 --> 00:17:38,290
In general,
feedback is to learn from examples.

250
00:17:38,290 --> 00:17:42,914
These examples can be assumed examples,
can be pseudo-examples,

251
00:17:42,914 --> 00:17:48,268
like assume the, the top ten
documents are assumed to be random.

252
00:17:48,268 --> 00:17:52,277
They could be based on using
fractions like feedback,

253
00:17:52,277 --> 00:17:55,260
based on quick sorts or implicit feedback.

254
00:17:55,260 --> 00:17:58,878
We talked about the three major
feedback scenarios, relevance feedback,

255
00:17:58,878 --> 00:18:02,010
pseudo-feedback, and implicit feedback.

256
00:18:02,010 --> 00:18:07,620
We talked about how to use Rocchio to
do feedback in vector-space model and

257
00:18:07,620 --> 00:18:14,260
how to use query model estimation for
feedback in language model.

258
00:18:14,260 --> 00:18:17,730
And we briefly talked about
the mixture model and

259
00:18:17,730 --> 00:18:21,650
the basic idea and
there are many other methods.

260
00:18:21,650 --> 00:18:25,080
For example the relevance model
is a very effective model for

261
00:18:25,080 --> 00:18:26,960
estimating query model.

262
00:18:26,960 --> 00:18:29,100
So, you can read more about the,

263
00:18:29,100 --> 00:18:34,690
these methods in the references that
are listed at the end of this lecture.

264
00:18:36,180 --> 00:18:38,400
So there are two additional readings here.

265
00:18:38,400 --> 00:18:42,920
The first one is a book that
has a systematic, review and

266
00:18:42,920 --> 00:18:45,055
discussion of language models
of more information retrieval.

267
00:18:46,560 --> 00:18:51,728
And the second one is an important
research paper that's about relevance

268
00:18:51,728 --> 00:18:56,989
based language models and it's a very
effective way of computing query model.

269
00:18:56,989 --> 00:19:06,989
[MUSIC]

