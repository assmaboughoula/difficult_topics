1
00:00:00,025 --> 00:00:06,228
[SOUND] This lecture is about

2
00:00:06,228 --> 00:00:13,587
natural language content analysis.

3
00:00:13,587 --> 00:00:15,499
As you see from this picture,

4
00:00:15,499 --> 00:00:19,540
this is really the first step
to process any text data.

5
00:00:19,540 --> 00:00:22,060
Text data are in natural languages.

6
00:00:22,060 --> 00:00:26,990
So, computers have to understand
natural languages to some extent in

7
00:00:26,990 --> 00:00:31,980
order to make use of the data, so
that's the topic of this lecture.

8
00:00:31,980 --> 00:00:33,910
We're going to cover three things.

9
00:00:33,910 --> 00:00:38,630
First, what is natural language
processing, which is a main technique for

10
00:00:38,630 --> 00:00:41,730
processing natural language
to obtain understanding?

11
00:00:43,150 --> 00:00:47,010
The second is the State of the Art in NLP,
which stands for

12
00:00:47,010 --> 00:00:48,360
natural language processing.

13
00:00:49,540 --> 00:00:53,470
Finally, we're going to cover the relation
between natural language processing and

14
00:00:53,470 --> 00:00:54,900
text retrieval.

15
00:00:54,900 --> 00:00:57,270
First, what is NLP?

16
00:00:57,270 --> 00:01:00,660
Well, the best way to
explain it is to think about,

17
00:01:00,660 --> 00:01:05,890
if you see a text in a foreign
language that you can't understand.

18
00:01:06,990 --> 00:01:10,990
Now, what you have to do in
order to understand that text?

19
00:01:10,990 --> 00:01:13,210
This is basically what
computers are facing.

20
00:01:13,210 --> 00:01:15,140
Right?
So, looking at the simple sentence like,

21
00:01:15,140 --> 00:01:17,650
a dog is chasing a boy on the playground.

22
00:01:18,730 --> 00:01:22,540
We don't have any problems
understanding this sentence, but

23
00:01:22,540 --> 00:01:25,950
imagine what the computer would have
to do in order to understand it.

24
00:01:25,950 --> 00:01:27,820
For in general,
it would have to do the following.

25
00:01:27,820 --> 00:01:34,310
First, it would have to know dog is
a noun, chasing's a verb, et cetera.

26
00:01:34,310 --> 00:01:38,290
So, this is a code lexile analysis or
part of speech tagging.

27
00:01:38,290 --> 00:01:42,230
And, we need to pick out the,
the syntaxing categories of those words.

28
00:01:42,230 --> 00:01:43,930
So, that's a first step.

29
00:01:43,930 --> 00:01:47,480
After that, we're going to figure
out the structure of the sentence.

30
00:01:47,480 --> 00:01:50,460
So for example, here it shows that a and

31
00:01:50,460 --> 00:01:54,270
dog would go together
to form a noun phrase.

32
00:01:55,710 --> 00:02:00,210
And, we won't have dog and
is to go first, right.

33
00:02:00,210 --> 00:02:02,969
And, there are some structures
that are not just right.

34
00:02:04,470 --> 00:02:09,630
But, this structure shows what we might
get if we look at the sentence and

35
00:02:09,630 --> 00:02:11,850
try to interpret the sentence.

36
00:02:11,850 --> 00:02:13,950
Some words would go together first, and

37
00:02:13,950 --> 00:02:15,640
then they will go together
with other words.

38
00:02:16,640 --> 00:02:20,200
So here, we show we have noun phrases
as intermediate components and

39
00:02:20,200 --> 00:02:21,510
then verb phrases.

40
00:02:21,510 --> 00:02:23,670
Finally, we have a sentence.

41
00:02:23,670 --> 00:02:28,440
And, you get this structure, we need to
do something called a syntactic analysis,

42
00:02:28,440 --> 00:02:29,440
or parsing.

43
00:02:29,440 --> 00:02:30,640
And, we may have a parser,

44
00:02:30,640 --> 00:02:34,980
a computer program that would
automatically create this structure.

45
00:02:34,980 --> 00:02:38,220
At this point, you would know
the structure of this sentence, but

46
00:02:38,220 --> 00:02:40,440
still you don't know
the meaning of the sentence.

47
00:02:40,440 --> 00:02:44,060
So, we have to go further
through semantic analysis.

48
00:02:44,060 --> 00:02:45,330
In our mind,

49
00:02:45,330 --> 00:02:51,250
we usually can map such a sentence to what
we already know in our knowledge base.

50
00:02:51,250 --> 00:02:53,930
And for example, you might imagine
a dog that looks like that,

51
00:02:53,930 --> 00:02:56,800
there's a boy and
there's some activity here.

52
00:02:56,800 --> 00:02:59,690
But for computer,
will have to use symbols to denote that.

53
00:02:59,690 --> 00:03:01,040
All right.

54
00:03:01,040 --> 00:03:05,220
So, we would use the symbol
d1 to denote a dog.

55
00:03:05,220 --> 00:03:10,420
And, b1 to denote a boy, and then p1
to denote the playground, playground.

56
00:03:12,650 --> 00:03:15,400
Now, there is also a chasing
activity that's happening here, so

57
00:03:15,400 --> 00:03:19,150
we have the relation chasing here,
that connects all these symbols.

58
00:03:19,150 --> 00:03:23,909
So, this is how a computer would obtain
some understanding of this sentence.

59
00:03:25,920 --> 00:03:31,590
Now from this representation, we could
also further infer some other things,

60
00:03:31,590 --> 00:03:35,270
and we might indeed, naturally think
of something else when we read text.

61
00:03:35,270 --> 00:03:37,470
And, this is call inference.

62
00:03:37,470 --> 00:03:42,490
So for example, if you believe
that if someone's being chased and

63
00:03:42,490 --> 00:03:44,470
this person might be scared.

64
00:03:44,470 --> 00:03:45,340
All right.

65
00:03:45,340 --> 00:03:46,180
With this rule,

66
00:03:46,180 --> 00:03:50,880
you can see computers could also
infer that this boy may be scared.

67
00:03:50,880 --> 00:03:54,040
So, this is some extra knowledge
that you would infer based on

68
00:03:54,040 --> 00:03:56,430
some understanding of the text.

69
00:03:56,430 --> 00:04:02,280
You can even go further to understand the,
why the person said this sentence.

70
00:04:02,280 --> 00:04:04,120
So, this has to do with
the use of language.

71
00:04:04,120 --> 00:04:05,160
All right.

72
00:04:05,160 --> 00:04:08,740
This is called pragmatic analysis.

73
00:04:08,740 --> 00:04:14,090
In order to understand the speech
actor of a sentence, all right,

74
00:04:14,090 --> 00:04:18,380
we say something to
basically achieve some goal.

75
00:04:18,380 --> 00:04:22,110
There's some purpose there and
this has to do with the use of language.

76
00:04:22,110 --> 00:04:24,770
In this case, the person who said

77
00:04:24,770 --> 00:04:29,200
the sentence might be reminding
another person to bring back the dog.

78
00:04:29,200 --> 00:04:31,470
That could be one possible intent.

79
00:04:33,020 --> 00:04:39,380
To reach this level of understanding,
we would require all these steps.

80
00:04:39,380 --> 00:04:43,800
And, a computer would have to go
through all these steps in order to

81
00:04:43,800 --> 00:04:46,940
completely understand this sentence.

82
00:04:46,940 --> 00:04:49,560
Yet, we humans have no
trouble with understand that.

83
00:04:49,560 --> 00:04:53,750
We instantly, will get everything,
and there is a reason for that.

84
00:04:53,750 --> 00:04:57,490
That's because we have a large
knowledge base in our brain, and

85
00:04:57,490 --> 00:05:01,890
we use common sense knowledge
to help interpret the sentence.

86
00:05:01,890 --> 00:05:06,340
Computers, unfortunately,
are hard to obtain such understanding.

87
00:05:06,340 --> 00:05:08,430
They don't have such a knowledge base.

88
00:05:08,430 --> 00:05:12,520
They are still incapable of doing
reasoning and uncertainties.

89
00:05:14,290 --> 00:05:18,430
So, that makes natural language
processing difficult for computers.

90
00:05:18,430 --> 00:05:21,400
But, the fundamental reason why the
natural language processing is difficult

91
00:05:21,400 --> 00:05:25,430
for computers is simple because natural
language has not been designed for

92
00:05:25,430 --> 00:05:26,440
computers.

93
00:05:26,440 --> 00:05:30,960
They, they, natural languages
are designed for us to communicate.

94
00:05:30,960 --> 00:05:33,480
There are other languages designed for
computers.

95
00:05:33,480 --> 00:05:36,200
For example, program languages.

96
00:05:36,200 --> 00:05:38,780
Those are harder for us, right.

97
00:05:38,780 --> 00:05:43,680
So, natural languages is designed to
make our communication efficient.

98
00:05:43,680 --> 00:05:46,770
As a result,
we omit a lot of common sense knowledge

99
00:05:46,770 --> 00:05:49,550
because we assume everyone
knows about that.

100
00:05:49,550 --> 00:05:54,140
We also keep a lot of ambiguities
because we assume the receiver, or

101
00:05:54,140 --> 00:05:59,340
the hearer could know how to
discern an ambiguous word,

102
00:05:59,340 --> 00:06:02,020
based on the knowledge or the context.

103
00:06:02,020 --> 00:06:05,340
There's no need to invent a different
word for different meanings.

104
00:06:05,340 --> 00:06:08,829
We could overload the same word with
different meanings without the problem.

105
00:06:10,460 --> 00:06:11,540
Because of these reasons,

106
00:06:11,540 --> 00:06:15,990
this makes every step in natural language
of processing difficult for computers.

107
00:06:15,990 --> 00:06:18,890
Ambiguity's the main difficulty, and

108
00:06:18,890 --> 00:06:22,050
common sense reasoning is often required,
that's also hard.

109
00:06:23,790 --> 00:06:26,356
So, let me give you some
examples of challenges here.

110
00:06:26,356 --> 00:06:30,740
Conceded the word-level ambiguities.

111
00:06:30,740 --> 00:06:34,490
The same word can have different
syntactical categories.

112
00:06:34,490 --> 00:06:36,770
For example,
design can be a noun or a verb.

113
00:06:39,280 --> 00:06:42,160
The word root may have multiple meanings.

114
00:06:42,160 --> 00:06:45,120
So, square root in math sense,
or the root of a plant.

115
00:06:46,450 --> 00:06:48,290
You might be able to
think of other meanings.

116
00:06:49,560 --> 00:06:52,766
There are also syntactical ambiguities.

117
00:06:52,766 --> 00:06:57,460
For example, the main topic of this
lecture, natural language processing,

118
00:06:57,460 --> 00:07:01,470
can actually be interpreted in two ways,
in terms of the structure.

119
00:07:01,470 --> 00:07:03,990
Think for a moment and
see if you can figure that out.

120
00:07:05,320 --> 00:07:09,730
We usually think of this as
processing of natural languages, but

121
00:07:09,730 --> 00:07:14,010
you could also think of this as you say,
language process is natural.

122
00:07:15,760 --> 00:07:20,410
Right.
So, this is example of syntatic ambiguity.

123
00:07:20,410 --> 00:07:23,170
Where we have different
structures that can be

124
00:07:24,510 --> 00:07:27,480
applied to the same sequence of words.

125
00:07:27,480 --> 00:07:31,730
Another example of ambiguous
sentence is the following,

126
00:07:31,730 --> 00:07:34,480
a man saw a boy with a telescope.

127
00:07:34,480 --> 00:07:37,600
Now, in this case, the question is,
who had the telescope?

128
00:07:37,600 --> 00:07:42,550
All right, this is called a prepositional
phrase attachment ambiguity,

129
00:07:42,550 --> 00:07:45,040
or PP attachment ambiguity.

130
00:07:45,040 --> 00:07:49,700
Now, we generally don't have a problem
with these ambiguities because we have

131
00:07:49,700 --> 00:07:54,320
a lot of background knowledge to
help us disintegrate the ambiguity.

132
00:07:55,380 --> 00:07:57,887
Another example of difficulty
is anaphora resolution.

133
00:07:57,887 --> 00:08:03,251
So, think about the sentence like John
persuaded Bill to buy a TV for himself.

134
00:08:03,251 --> 00:08:07,616
The question here is,
does himself refer to John or Bill?

135
00:08:07,616 --> 00:08:10,834
So again, this is something that
you have to use some background or

136
00:08:10,834 --> 00:08:12,530
the context to figure out.

137
00:08:12,530 --> 00:08:15,470
Finally, presupposition
is another problem.

138
00:08:15,470 --> 00:08:18,100
Consider the sentence,
he has quit smoking.

139
00:08:18,100 --> 00:08:20,710
Now this obviously
implies he smoked before.

140
00:08:22,430 --> 00:08:27,350
So, imagine a computer wants to understand
all the subtle differences and meanings.

141
00:08:27,350 --> 00:08:30,938
They would have to use a lot of
knowledge to figure that out.

142
00:08:30,938 --> 00:08:35,900
It also would have to maintain a large
knowl, knowledge base of odd meanings of

143
00:08:35,900 --> 00:08:41,940
words and how they are connected to our
common sense knowledge of the word.

144
00:08:41,940 --> 00:08:44,120
So this is why it's very difficult.

145
00:08:45,530 --> 00:08:49,110
So as a result we are still not perfect.

146
00:08:49,110 --> 00:08:54,240
In fact, far from perfect in understanding
natural languages using computers.

147
00:08:54,240 --> 00:09:00,230
So this slide sort of gives a simplified
view of state of the art technologies.

148
00:09:01,580 --> 00:09:05,000
We can do part of speech
tagging pretty well.

149
00:09:05,000 --> 00:09:09,620
So, I showed minus 7% accuracy here.

150
00:09:09,620 --> 00:09:13,830
Now this number is obviously
based on a certain data set, so

151
00:09:13,830 --> 00:09:15,060
don't take this literally.

152
00:09:15,060 --> 00:09:18,210
All right, this just shows that
we could do it pretty well.

153
00:09:18,210 --> 00:09:20,320
But it's still not perfect.

154
00:09:20,320 --> 00:09:23,620
In terms of parsing,
we can do partial parsing pretty well.

155
00:09:23,620 --> 00:09:28,240
That means we can get noun phrase
structures or verb phrase structure, or

156
00:09:28,240 --> 00:09:33,439
some segment of the sentence understood
correctly in terms of the structure.

157
00:09:34,470 --> 00:09:38,390
And, in some evaluation
results we have seen about 90%

158
00:09:38,390 --> 00:09:43,140
accuracy in terms of partial
parsing of sentences.

159
00:09:43,140 --> 00:09:46,910
Again, I have to say, these numbers
are relative to the data set.

160
00:09:46,910 --> 00:09:50,310
In some other data sets,
the numbers might be lower.

161
00:09:50,310 --> 00:09:54,230
Most of existing work has been
evaluated using news data set.

162
00:09:54,230 --> 00:09:59,800
And so, a lot of these numbers are more or
less biased towards news data.

163
00:09:59,800 --> 00:10:01,570
Think about social media data.

164
00:10:01,570 --> 00:10:02,980
The accuracy likely is lower.

165
00:10:05,450 --> 00:10:07,860
In terms of semantic analysis,

166
00:10:07,860 --> 00:10:13,730
we are far from being able to do
a complete understanding of a sentence.

167
00:10:13,730 --> 00:10:16,570
But we have some techniques
that would allow us to do

168
00:10:16,570 --> 00:10:18,890
partial understanding of the sentence.

169
00:10:18,890 --> 00:10:22,360
So, I could mention some of them.

170
00:10:22,360 --> 00:10:27,190
For example, we have techniques that can
allow us to extract the entities and

171
00:10:27,190 --> 00:10:30,310
relations mentioned in text or articles.

172
00:10:30,310 --> 00:10:34,661
For example, recognizing
the mentions of people, locations,

173
00:10:34,661 --> 00:10:37,120
organizations, et cetera in text.

174
00:10:37,120 --> 00:10:40,930
Right?
So this is called entity extraction.

175
00:10:40,930 --> 00:10:42,980
We may be able to recognize the relations.

176
00:10:42,980 --> 00:10:47,220
For example,
this person visited that per, that place.

177
00:10:47,220 --> 00:10:51,340
Or, this person met that person, or
this company acquired another company.

178
00:10:51,340 --> 00:10:54,870
Such relations can be extracted
by using the current and

179
00:10:54,870 --> 00:10:56,800
natural languaging processing techniques.

180
00:10:56,800 --> 00:11:00,170
They are not perfect, but
they can do well for some entities.

181
00:11:00,170 --> 00:11:03,010
Some entities are harder than others.

182
00:11:03,010 --> 00:11:05,660
We can also do word sentence
disintegration to some extent.

183
00:11:05,660 --> 00:11:10,240
We have to figure out whether this word in
this sentence would have certain meaning,

184
00:11:10,240 --> 00:11:12,310
and in another context,

185
00:11:12,310 --> 00:11:15,250
the computer could figure out
that it has a different meaning.

186
00:11:15,250 --> 00:11:18,160
Again, it's not perfect but
you can do something in that direction.

187
00:11:19,530 --> 00:11:22,040
We can also do sentiment analysis meaning

188
00:11:22,040 --> 00:11:25,850
to figure out whether sentence
is positive or negative.

189
00:11:25,850 --> 00:11:28,950
This is a special use for, for
review analysis for example.

190
00:11:30,410 --> 00:11:33,150
So these examples of semantic analysis.

191
00:11:33,150 --> 00:11:38,470
And they help us to obtain partial
understanding of the sentences.

192
00:11:38,470 --> 00:11:39,510
Right?
It's not

193
00:11:39,510 --> 00:11:44,490
giving us a complete understanding as
I showed before for the sentence, but

194
00:11:44,490 --> 00:11:49,570
it will still help us gain understanding
of the content and these can be useful.

195
00:11:51,620 --> 00:11:54,660
In terms of inference,
we are not yet there,

196
00:11:54,660 --> 00:11:59,950
probably because of the general difficulty
of inference and uncertainties.

197
00:11:59,950 --> 00:12:03,053
This is a general challenge
in artificial intelligence.

198
00:12:03,053 --> 00:12:08,427
That's probably also because we don't have
complete semantic reimplementation for

199
00:12:08,427 --> 00:12:10,120
natural language text.

200
00:12:10,120 --> 00:12:11,310
So this is hard.

201
00:12:11,310 --> 00:12:16,540
Yet in some domains, perhaps in
limited domains when you have a lot of

202
00:12:16,540 --> 00:12:21,670
restrictions on the world of users,
you may be to may be able to perform

203
00:12:21,670 --> 00:12:27,194
inference to some extent, but in general
we cannot really do that reliably.

204
00:12:27,194 --> 00:12:31,610
Speech act analysis is also
far from being done, and

205
00:12:31,610 --> 00:12:36,600
we can only do that analysis for
very special cases.

206
00:12:36,600 --> 00:12:40,700
So, this roughly gives you some
idea about the state of the art.

207
00:12:41,950 --> 00:12:44,740
And let me also talk a little
bit about what we can't do.

208
00:12:44,740 --> 00:12:52,068
And, and so we can't even do
100% part of speech tagging.

209
00:12:52,068 --> 00:12:56,727
This looks like a simple task,
but think about the example here,

210
00:12:56,727 --> 00:13:01,641
the two uses of off may have different
syntactic categories if you try

211
00:13:01,641 --> 00:13:04,830
to make a fine grain distinctions.

212
00:13:04,830 --> 00:13:07,620
It's not that easy to figure
out such differences.

213
00:13:10,000 --> 00:13:12,900
It's also hard to do general
complete the parsing.

214
00:13:12,900 --> 00:13:16,960
And, again this same sentence
that you saw before is example.

215
00:13:18,010 --> 00:13:21,568
This, this ambiguity can be
very hard to disambiguate.

216
00:13:21,568 --> 00:13:26,000
And you can imagine example where you
have to use a lot of knowledge i,

217
00:13:26,000 --> 00:13:27,900
in the context of the sentence or

218
00:13:27,900 --> 00:13:33,310
from the background in order to figure
out the, who actually had the telescope.

219
00:13:33,310 --> 00:13:37,730
So is, i, although sentence looks very
simple, it actually is pretty hard.

220
00:13:37,730 --> 00:13:42,526
And in cases when the sentence is
very long, imagine it has four or

221
00:13:42,526 --> 00:13:46,759
five prepositional phrases, then there
are even more possibilities to figure out.

222
00:13:48,580 --> 00:13:51,650
It's also harder to precise
deep semantic analysis.

223
00:13:51,650 --> 00:13:52,720
So here's example.

224
00:13:53,808 --> 00:14:00,095
In this sentence, John owns a restaurant,
how do we define owns exactly?

225
00:14:00,095 --> 00:14:05,330
The word, own, you know,
is something that we can understand but

226
00:14:05,330 --> 00:14:10,210
it's very hard to precisely describe
the meaning of own for computers.

227
00:14:11,430 --> 00:14:16,220
So as a result we have robust and

228
00:14:16,220 --> 00:14:20,963
general natural language processing
techniques that can process a lot of text

229
00:14:20,963 --> 00:14:25,640
data in a shallow way,
meaning we only do superficial analysis.

230
00:14:25,640 --> 00:14:28,250
For example, part of s,
of speech tagging, or

231
00:14:28,250 --> 00:14:33,600
partial parsing, or recognizing sentiment.

232
00:14:33,600 --> 00:14:36,930
And those are not deep understanding
because we're not really

233
00:14:36,930 --> 00:14:39,419
understanding the exact
meaning of the sentence.

234
00:14:41,270 --> 00:14:45,870
On the other hand, the deep understanding
techniques tend not to scale up well,

235
00:14:45,870 --> 00:14:50,830
meaning that they would fail
on some unrestricted text.

236
00:14:50,830 --> 00:14:54,860
And if you don't restrict
the text domain or

237
00:14:54,860 --> 00:14:59,720
the use of words, then these
techniques tend not to work well.

238
00:14:59,720 --> 00:15:04,310
They may work well, based on machine
learning techniques on the data

239
00:15:04,310 --> 00:15:08,520
that are similar to the training data
that the program has been trained on.

240
00:15:08,520 --> 00:15:13,110
But they generally wouldn't work well on
the data that are very different from

241
00:15:13,110 --> 00:15:14,290
the training data.

242
00:15:14,290 --> 00:15:19,160
So this pretty much summarizes the state
of the art of natural language processing.

243
00:15:19,160 --> 00:15:23,610
Of course, within such a short amount
of time, we can't really give you a,

244
00:15:23,610 --> 00:15:29,800
a complete view of any of it, which is a
big field, and either expect that to have,

245
00:15:29,800 --> 00:15:35,890
to see multiple courses on natural
language processing topic itself.

246
00:15:35,890 --> 00:15:40,970
But, because of it's relevance to the
topic that we talked about it's useful for

247
00:15:40,970 --> 00:15:45,410
you to know the background in case
you haven't been exposed to that.

248
00:15:45,410 --> 00:15:47,340
So, what does that mean for
text retrieval?

249
00:15:48,980 --> 00:15:53,188
Well, in text retrieval we
are dealing with all kinds of text.

250
00:15:53,188 --> 00:15:56,903
It's very hard to restrict
the text to a certain domain.

251
00:15:56,903 --> 00:16:01,384
And we also are often dealing with
a lot of text data, so that means.

252
00:16:01,384 --> 00:16:06,475
The NLP techniques must be general,
robust, and efficient and that

253
00:16:06,475 --> 00:16:12,828
just implies today we can only use fairly
shallow NLP techniques for text retrieval.

254
00:16:12,828 --> 00:16:14,174
In fact,

255
00:16:14,174 --> 00:16:19,070
most search engines today use something
called a bag of words representation.

256
00:16:20,740 --> 00:16:25,450
Now this is probably the simplest
representation you can probably think of.

257
00:16:25,450 --> 00:16:29,250
That is to turn text data
into simply a bag of words.

258
00:16:29,250 --> 00:16:33,930
Meaning we will keep the individual words
but we'll ignore all the orders of words.

259
00:16:33,930 --> 00:16:37,660
And we'll keep duplicated
occurrences of words.

260
00:16:37,660 --> 00:16:39,930
So this is called a bag
of words representation.

261
00:16:39,930 --> 00:16:44,900
When you represent the text in this way,
you ignore a lot about the information,

262
00:16:44,900 --> 00:16:48,120
and that just makes it harder

263
00:16:48,120 --> 00:16:52,460
to understand the exact meaning of
a sentence because we've lost the order.

264
00:16:53,870 --> 00:16:57,320
But yet, this representation tends
to actually work pretty well for

265
00:16:57,320 --> 00:16:59,150
most search tasks.

266
00:16:59,150 --> 00:17:03,440
And this is partly because the search
task is not all that difficult.

267
00:17:03,440 --> 00:17:08,720
If you see matching of some of the query
words in a text document, chances

268
00:17:08,720 --> 00:17:13,670
are that that document is about the topic,
although there are exceptions, right?

269
00:17:13,670 --> 00:17:18,160
So in comparison some other tasks, for
example machine translation, would require

270
00:17:18,160 --> 00:17:22,670
you to understand the language accurately,
otherwise the translation would be wrong.

271
00:17:22,670 --> 00:17:23,435
So in comparison,

272
00:17:23,435 --> 00:17:28,860
search tasks are solved relatively easy
such a representation is often sufficient.

273
00:17:28,860 --> 00:17:32,060
And that's also the representation
that the major search engines today,

274
00:17:32,060 --> 00:17:34,060
like Google or Bing are using.

275
00:17:35,760 --> 00:17:38,112
Of course I put in in parentheses but
not all.

276
00:17:38,112 --> 00:17:42,237
Of course there are many queries that are
not answered well by the current search

277
00:17:42,237 --> 00:17:45,300
engines, and
they do require a representation

278
00:17:45,300 --> 00:17:48,310
that would go beyond bag
of words representation.

279
00:17:48,310 --> 00:17:52,051
That would require more natural
language processing, to be done.

280
00:17:52,051 --> 00:17:56,780
There is another reason why we have
not used the sophisticated NLP

281
00:17:56,780 --> 00:18:01,970
techniques in modern search engines, and
that's because some retrieval techniques

282
00:18:01,970 --> 00:18:05,400
actually naturally solve
the problem of NLP.

283
00:18:05,400 --> 00:18:09,250
So, one example,
is word sense disambiguation.

284
00:18:09,250 --> 00:18:11,060
Think about a word like java.

285
00:18:11,060 --> 00:18:13,915
It could mean coffee or
it could mean program language.

286
00:18:15,070 --> 00:18:18,080
If you look at the word
alone it would be ambiguous.

287
00:18:18,080 --> 00:18:23,040
But when the user uses the water in
the query, usually there are other words.

288
00:18:23,040 --> 00:18:26,240
For example I'm looking for
usage of Java applet.

289
00:18:26,240 --> 00:18:31,990
When I have applet there that
implies Java means program language.

290
00:18:31,990 --> 00:18:35,040
And that context can help us naturally

291
00:18:35,040 --> 00:18:39,680
prefer documents where Java is
referring to program language,

292
00:18:39,680 --> 00:18:43,710
because those documents would
probably match applet as well.

293
00:18:43,710 --> 00:18:47,722
If java occurs in the document
in a way that means coffee,

294
00:18:47,722 --> 00:18:53,250
then you would never match applet,
or with very small probability.

295
00:18:53,250 --> 00:18:55,400
Right.
So this is a case when some retrieval

296
00:18:55,400 --> 00:18:59,755
techniques naturally achieve the goal
of word sense disambiguation.

297
00:19:01,530 --> 00:19:05,920
Another example is some technique called

298
00:19:05,920 --> 00:19:11,362
feedback which we will talk about
later in some of the lectures.

299
00:19:11,362 --> 00:19:17,410
This tech, technique would allow us
to add additional words to the query.

300
00:19:17,410 --> 00:19:22,100
And those additional words could
be related to the query words.

301
00:19:22,100 --> 00:19:26,540
And these words can help match documents
where the original query words

302
00:19:26,540 --> 00:19:27,680
have not occurred.

303
00:19:27,680 --> 00:19:32,490
So this achieves, to some extent,
semantic matching of terms.

304
00:19:32,490 --> 00:19:35,350
So those techniques also helped us

305
00:19:35,350 --> 00:19:38,890
bypass some of the difficulties
in natural language processing.

306
00:19:40,530 --> 00:19:43,930
However, in the long run, we still need
deeper natural language processing

307
00:19:43,930 --> 00:19:47,280
techniques in order to improve the
accuracy of the current search engines.

308
00:19:47,280 --> 00:19:53,390
And it's particularly needed for complex
search tasks, or for question answering.

309
00:19:55,320 --> 00:19:58,910
Google has recently
launched a knowledge graph.

310
00:19:58,910 --> 00:20:01,100
And this is one step toward that goal,

311
00:20:01,100 --> 00:20:05,180
because knowledge graph would contain
entities and their relations.

312
00:20:05,180 --> 00:20:09,035
And this goes beyond the simple
bag of words representation.

313
00:20:09,035 --> 00:20:14,870
And such technique should help us improve
the search engine utility significantly,

314
00:20:14,870 --> 00:20:19,220
although this is a still open topic for
research and exploration.

315
00:20:19,220 --> 00:20:25,480
In sum, in this lecture we'll talk
about what is NLP and we've talked

316
00:20:25,480 --> 00:20:30,540
about the state of the art techniques,
what we can do, what we cannot do.

317
00:20:30,540 --> 00:20:34,530
And finally, we also explained
why bag of words representation

318
00:20:34,530 --> 00:20:39,420
remains the dominant representation used
in modern search engines even though

319
00:20:39,420 --> 00:20:42,696
deeper NLP would be needed for
future search engines.

320
00:20:42,696 --> 00:20:46,415
If you want to know more you can take
a look at some additional readings.

321
00:20:46,415 --> 00:20:47,590
I only cited one here.

322
00:20:47,590 --> 00:20:48,528
And that's a good starting point though.

323
00:20:48,528 --> 00:20:50,499
Thanks.

324
00:20:50,499 --> 00:21:00,499
[MUSIC]

