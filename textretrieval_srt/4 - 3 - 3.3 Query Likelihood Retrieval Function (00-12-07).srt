1
00:00:07,880 --> 00:00:11,960
This lecture is about query likelihood and
probabilistic retrieval model.

2
00:00:14,040 --> 00:00:15,310
In this lecture,

3
00:00:15,310 --> 00:00:19,180
we continue the discussion of
probabilistic retrieval model.

4
00:00:19,180 --> 00:00:20,409
In particular,

5
00:00:20,409 --> 00:00:25,870
we're going to talk about the query
likelihood of the retrieval function.

6
00:00:25,870 --> 00:00:31,270
In the query of likelihood retrieval
model our idea is a model.

7
00:00:31,270 --> 00:00:35,420
How a likely a user, who likes a document
would pose a particular query.

8
00:00:36,980 --> 00:00:39,960
So in this case, you can imagine,

9
00:00:39,960 --> 00:00:45,600
if a user likes this particular document
about the presidential campaign news.

10
00:00:46,840 --> 00:00:51,030
Then we can assume,
the user would use this

11
00:00:51,030 --> 00:00:54,670
working as a basis to oppose a query
to try and retrieve this doc.

12
00:00:57,260 --> 00:01:04,060
So you can imagine the user, could use
a process that works as follows, where

13
00:01:04,060 --> 00:01:08,630
we assume that the query is generated
by sampling words from the document.

14
00:01:10,560 --> 00:01:15,310
So for example,
a user might pick a word like

15
00:01:15,310 --> 00:01:19,420
presidential from this document,
and then use this as a query word.

16
00:01:20,600 --> 00:01:24,590
And then the user would pick another word,
like campaign and

17
00:01:24,590 --> 00:01:25,900
that would be the second query word.

18
00:01:27,420 --> 00:01:28,720
Now this, of course,

19
00:01:28,720 --> 00:01:33,500
is assumption that we have made about,
how a user would post a query.

20
00:01:35,170 --> 00:01:38,630
Whether a user actually
followed this process.

21
00:01:38,630 --> 00:01:39,810
Maybe a different question.

22
00:01:39,810 --> 00:01:41,170
But this assumption,

23
00:01:41,170 --> 00:01:45,290
has allowed us to formally characterize
this conditional probability.

24
00:01:46,390 --> 00:01:50,860
And this allows to also not rely on
the big table that I showed you earlier

25
00:01:52,580 --> 00:01:55,750
to use imperative data to
estimate this probability.

26
00:01:56,860 --> 00:02:00,820
And this is why we can use this
idea to then further derive

27
00:02:00,820 --> 00:02:03,569
retrieval function that we can
implement with the languages.

28
00:02:04,900 --> 00:02:09,390
So, as you see, the assumption that
we've made here is, each query word,

29
00:02:09,390 --> 00:02:12,790
is independent in this sample, and also,

30
00:02:12,790 --> 00:02:17,880
each word is basically
obtained from the document.

31
00:02:20,910 --> 00:02:24,540
So now let's see how this works exactly.

32
00:02:24,540 --> 00:02:28,370
Well, since we are computing
a query likelihood,

33
00:02:29,770 --> 00:02:35,050
then the probability here is just
the probability of this particular query,

34
00:02:35,050 --> 00:02:37,210
which is a sequence of words.

35
00:02:37,210 --> 00:02:42,140
And we make the assumption that each
word is generated independently.

36
00:02:42,140 --> 00:02:46,610
So, as a result, the probability
of the query is just a product

37
00:02:46,610 --> 00:02:48,920
of the probability of each query word.

38
00:02:50,090 --> 00:02:52,660
Now, how do we compute
the probability of each query word?

39
00:02:52,660 --> 00:02:54,370
Well, based on the assumption,

40
00:02:54,370 --> 00:03:00,440
that a word is picked from the document,
that the user has in mind.

41
00:03:00,440 --> 00:03:03,725
Now we know the probability
of each word is just the,

42
00:03:03,725 --> 00:03:08,120
the relative frequency of
the word in the document.

43
00:03:08,120 --> 00:03:13,780
So, for example the probability of
presidential given the document,

44
00:03:13,780 --> 00:03:17,470
would be just the count of
presidential in the document,

45
00:03:17,470 --> 00:03:20,920
divided by the total number of words
in the document or document length.

46
00:03:23,050 --> 00:03:27,760
So with this these assumptions,
we now have actual simple formula for

47
00:03:27,760 --> 00:03:28,940
retrieval, right?

48
00:03:28,940 --> 00:03:30,910
We can use this to rank our document.

49
00:03:30,910 --> 00:03:34,190
So does this model work?

50
00:03:34,190 --> 00:03:38,670
Let's take a look, here are some example
documents that you have seen before.

51
00:03:38,670 --> 00:03:41,770
Suppose now the query is
presidential campaign.

52
00:03:41,770 --> 00:03:45,890
And we see the formula here on the top.

53
00:03:45,890 --> 00:03:47,490
So how do we score these documents?

54
00:03:47,490 --> 00:03:50,710
Well it's very simple, right,
we just count how many times we have seen

55
00:03:50,710 --> 00:03:54,388
presidential, how many times
we have seen campaign etc.

56
00:03:54,388 --> 00:03:57,620
And see here 44 and
we've seen president Jou Tai,

57
00:03:57,620 --> 00:04:01,125
so that's two over the lands
of document the four.

58
00:04:01,125 --> 00:04:06,200
Multiply by 1 over lands of document
of 4 for the probability of

59
00:04:06,200 --> 00:04:11,250
campaign and seeming we can probabilities
for the other two documents.

60
00:04:13,380 --> 00:04:18,560
Now if you'll look at this, these numbers
or these, this, these formulas for

61
00:04:18,560 --> 00:04:25,200
scoring all these documents, it seems to
make sense because, if we assume d3 and

62
00:04:25,200 --> 00:04:29,960
d4 have about the same length,
then it looks like we will rank d4

63
00:04:31,250 --> 00:04:36,140
above d3 and which is above d2, right?

64
00:04:36,140 --> 00:04:42,030
And as we would expect, looks like
it did capture the tf heuristic.

65
00:04:42,030 --> 00:04:44,710
And so this seems to work well.

66
00:04:46,530 --> 00:04:50,107
However, if we try a different
query like this one,

67
00:04:50,107 --> 00:04:54,350
presidential campaign update,
then we might see a problem.

68
00:04:55,600 --> 00:04:56,770
But what problem?

69
00:04:56,770 --> 00:05:02,500
Well, think about update, now none of
these documents has mentioned update.

70
00:05:02,500 --> 00:05:07,600
So according to our assumption that
a user would pick a order from a document

71
00:05:07,600 --> 00:05:09,420
to generate a query,

72
00:05:09,420 --> 00:05:15,110
then the probability of obtaining
a word like update would be what.

73
00:05:15,110 --> 00:05:16,070
Would be zero, right?

74
00:05:17,230 --> 00:05:21,380
So that cause a problem,
because it would cause all these documents

75
00:05:21,380 --> 00:05:23,730
to have zero probability
of generating this query.

76
00:05:25,330 --> 00:05:31,640
Now, while it's fine to have a zero
probability for d2 which is not relevant.

77
00:05:31,640 --> 00:05:34,658
It's not okay to have zero for d3 and

78
00:05:34,658 --> 00:05:38,600
d4, because now we no longer
can distinguish them.

79
00:05:38,600 --> 00:05:41,890
What's worse,
we can't even distinguish them from d 2.

80
00:05:41,890 --> 00:05:45,700
All right, so
that's obviously not desirable.

81
00:05:45,700 --> 00:05:50,960
Now when one has such result, we should
think about what has caused this problem.

82
00:05:52,490 --> 00:05:55,580
So we have to examine what
assumptions have been made,

83
00:05:56,700 --> 00:05:58,670
as we derive this ranking function.

84
00:05:59,830 --> 00:06:03,040
Now if you examine those assumptions
carefully you would realize.

85
00:06:03,040 --> 00:06:06,690
What has caused this problem, right?

86
00:06:06,690 --> 00:06:11,490
So, take a moment to think about,
what do you think is the reason why

87
00:06:11,490 --> 00:06:14,900
update has zero probability,
and how do we fix it?

88
00:06:17,650 --> 00:06:18,240
Right?

89
00:06:18,240 --> 00:06:21,420
So, if you think about this for
the moment that you realize that.

90
00:06:21,420 --> 00:06:23,880
That's because we have made an assumption

91
00:06:23,880 --> 00:06:29,220
that every query word must be drawn
from the document in the user's mind.

92
00:06:29,220 --> 00:06:32,010
So, in order to fix this,
we have to assume that,

93
00:06:32,010 --> 00:06:36,350
the user could have drawn a word,
not necessarily from the document.

94
00:06:36,350 --> 00:06:38,930
So let's see improved model.

95
00:06:38,930 --> 00:06:40,720
An improvement here is to say that,

96
00:06:40,720 --> 00:06:45,300
well, instead of drawing a word from
the document, let's imagine that the user

97
00:06:45,300 --> 00:06:50,260
would actually draw a word from a document
model and so I show a model here.

98
00:06:50,260 --> 00:06:53,240
Here we assume that this
document is generated,

99
00:06:53,240 --> 00:06:55,920
by using this unigram image model.

100
00:06:55,920 --> 00:07:01,560
Now, this model, doesn't necessarily
assign zero probability for update.

101
00:07:01,560 --> 00:07:05,460
In fact we assume this model does not
assign zero probability for any word.

102
00:07:05,460 --> 00:07:08,940
Now if we're thinking this
way then the generation

103
00:07:08,940 --> 00:07:10,700
process is a little bit different.

104
00:07:10,700 --> 00:07:14,980
Now the user has this model in mind,
instead of this particular document.

105
00:07:14,980 --> 00:07:17,400
Although the model has to be
estimated based on the document.

106
00:07:17,400 --> 00:07:22,920
So the user can again generate
the query using a similar process.

107
00:07:22,920 --> 00:07:27,680
They may pick a word, for example
presidential and another word campaign.

108
00:07:29,010 --> 00:07:32,390
Now the difference is that, this time
we can also pick a word like update,

109
00:07:32,390 --> 00:07:34,950
even though update it
doesn't occur in the document

110
00:07:34,950 --> 00:07:38,040
to potentially generate
a query word like update.

111
00:07:38,040 --> 00:07:43,830
So that, a query was updated we
want to have zero probabilities.

112
00:07:43,830 --> 00:07:46,790
So this would fix our problem and
it's also reasonable,

113
00:07:46,790 --> 00:07:51,260
because we're now thinking of what the
user is looking for in a more general way,

114
00:07:51,260 --> 00:07:55,160
that is unique language model
instead of a fixed document.

115
00:07:55,160 --> 00:07:56,700
So how do we compute this query,

116
00:07:56,700 --> 00:08:01,000
like if we make this sum where
it involves two steps, right?

117
00:08:01,000 --> 00:08:06,137
The first is the computer's model, and we
call it talking the language model here.

118
00:08:07,390 --> 00:08:12,310
For example, I have shown two
possible energy models here.

119
00:08:12,310 --> 00:08:15,060
This has been based on two documents.

120
00:08:15,060 --> 00:08:17,160
And then given a query and
I get a mining algorithms.

121
00:08:17,160 --> 00:08:22,700
The second step, is just to compute
the likelihood of this query.

122
00:08:22,700 --> 00:08:27,210
And by making independence assumptions,
we could then have this probability as

123
00:08:27,210 --> 00:08:29,700
a product of the probability
of each query word, all right?

124
00:08:30,900 --> 00:08:32,370
But we do this for both documents.

125
00:08:32,370 --> 00:08:35,710
And then we're going to score these
two documents and then rank them.

126
00:08:37,160 --> 00:08:41,310
So that's the basic idea of this
query likelihood retrieval function.

127
00:08:41,310 --> 00:08:48,050
So more generally than this ranking
function would look like the following and

128
00:08:48,050 --> 00:08:53,917
here as, we assume that query
has end words W1 through WN.

129
00:08:53,917 --> 00:09:01,130
And then the scoring function,
the ranking function is the probability

130
00:09:01,130 --> 00:09:06,080
that we observe this query, given that
the user is thinking of this document.

131
00:09:06,080 --> 00:09:11,970
And this assumed to be product of
probabilities of all individual words and

132
00:09:11,970 --> 00:09:13,819
this is based on
the independence assumption.

133
00:09:15,560 --> 00:09:19,260
Now we actually often score the,
document for

134
00:09:19,260 --> 00:09:25,240
this query by using log of the query
likelihood, as shown on the sigma line.

135
00:09:26,710 --> 00:09:32,560
Now we do this to avoid having
a lot of small probabilities.

136
00:09:34,280 --> 00:09:35,830
M, multiplied together.

137
00:09:35,830 --> 00:09:38,190
And this could cause underflow and

138
00:09:38,190 --> 00:09:44,100
we might lose precision by transforming
the value as a logarithm function.

139
00:09:44,100 --> 00:09:50,430
We maintain the order of these documents,
yet we can avoid the end of flow problem.

140
00:09:52,860 --> 00:09:57,051
So if we take longer than transformation
of coarse the product that would become

141
00:09:57,051 --> 00:09:59,920
a sum, as you stake in the line here.

142
00:09:59,920 --> 00:10:03,620
So it's a sum of all of the query words,
and inside the sum

143
00:10:03,620 --> 00:10:07,670
that is log of the probability of
this word given by the document.

144
00:10:09,360 --> 00:10:13,170
And then we can further rewrite the sum,
into a different form.

145
00:10:14,310 --> 00:10:19,950
So in the first of the sum here,
in this sum,

146
00:10:21,910 --> 00:10:25,120
we have it over all the query
words n query words.

147
00:10:28,790 --> 00:10:33,180
And in this sum, we have a sum
of all the possible words but

148
00:10:33,180 --> 00:10:37,050
we put a counter here of
each word in the query.

149
00:10:37,050 --> 00:10:39,780
Essentially we are only considering
the words in the query,

150
00:10:39,780 --> 00:10:43,520
because if a word is not in the query,
it can would be zero.

151
00:10:43,520 --> 00:10:46,770
So we're still considering
only these end words.

152
00:10:46,770 --> 00:10:50,900
But we're using a different form as if
we were going to a sum of all the words,

153
00:10:50,900 --> 00:10:51,570
in the vocabulary.

154
00:10:52,960 --> 00:10:56,435
And of course a word might occur
multiple times in the query.

155
00:10:56,435 --> 00:10:58,375
That's wh, why we have a count here.

156
00:11:01,080 --> 00:11:03,555
And then this part is

157
00:11:03,555 --> 00:11:06,865
log of the probability of the word
given by the document MG model.

158
00:11:08,617 --> 00:11:11,527
So you can see, in this material function,

159
00:11:11,527 --> 00:11:13,547
we actually know the count
of the word in the query.

160
00:11:13,547 --> 00:11:16,467
So, the only thing that we don't know
is this document language model.

161
00:11:17,817 --> 00:11:21,310
Therefore, we can convert
through the retrieval problem

162
00:11:21,310 --> 00:11:24,504
into the problem of estimating
this document language model.

163
00:11:24,504 --> 00:11:30,340
So that we can compute, the probability of
each query we're given by this document.

164
00:11:32,250 --> 00:11:36,610
At different estimation methods here,
would lead to different ranking functions.

165
00:11:36,610 --> 00:11:40,430
And this is just like a different
a ways to place a doc in the vector,

166
00:11:40,430 --> 00:11:42,030
in the vector space.

167
00:11:42,030 --> 00:11:45,670
Would lead it to a different ranking
function in the vector space model.

168
00:11:45,670 --> 00:11:50,436
Here are different ways to estimate
this stuff in the language model,

169
00:11:50,436 --> 00:11:55,459
will lead you to a different ranking
function for query likelihood.

170
00:11:55,459 --> 00:12:05,459
[MUSIC]

