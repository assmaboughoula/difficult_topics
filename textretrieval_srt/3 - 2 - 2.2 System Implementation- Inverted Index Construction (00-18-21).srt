1
00:00:00,012 --> 00:00:03,256
[SOUND].

2
00:00:07,388 --> 00:00:11,160
This lecture is about
the Inverted Index Construction.

3
00:00:13,840 --> 00:00:18,520
In this lecture, we will continue
the discussion of system implementation.

4
00:00:18,520 --> 00:00:21,892
In particular, we're going to discuss
how to construct the inverted index.

5
00:00:25,096 --> 00:00:29,290
The construction of the inverted index
is actually very easy if the data set is

6
00:00:29,290 --> 00:00:30,450
very small.

7
00:00:30,450 --> 00:00:35,430
It's very easy to construct a dictionary
and then store the postings in a file.

8
00:00:36,610 --> 00:00:41,959
The problem's that when our data
is not able to fit to the memory,

9
00:00:41,959 --> 00:00:46,444
then we have to use some
special method to deal with it.

10
00:00:46,444 --> 00:00:52,125
And unfortunately, in most retrieval a
petitions, the data set would be large and

11
00:00:52,125 --> 00:00:56,520
they generally cannot be,
loaded into the memory at once.

12
00:00:56,520 --> 00:01:00,725
And there are many approaches
to solving that problem, and

13
00:01:00,725 --> 00:01:06,710
sorting-based method, is quite common and
works in four steps as shown here.

14
00:01:06,710 --> 00:01:11,480
First, we collect the the local termID,
document ID, and frequency tuples.

15
00:01:11,480 --> 00:01:17,790
Basically, you overlook kinds of terms
in a small set of documents, and, and

16
00:01:17,790 --> 00:01:24,570
then, once you collect those counts, you
can sort those counts based on terms so

17
00:01:24,570 --> 00:01:28,680
that you build a local,
a partial inverted index.

18
00:01:28,680 --> 00:01:31,310
And these are called, runs.

19
00:01:31,310 --> 00:01:36,840
And then, you write them into
a temporary file on the disk.

20
00:01:36,840 --> 00:01:41,731
And then, you merge in step three with do
pair-wise merging of these runs, and here,

21
00:01:41,731 --> 00:01:45,890
you eventually merge all the runs,
we generate a single inverted index.

22
00:01:47,520 --> 00:01:51,010
So this is an illustration of this method.

23
00:01:51,010 --> 00:01:52,299
On the left, you see some documents.

24
00:01:53,640 --> 00:01:59,930
And on the right, we have, show a term
lexicon and a document ID lexicon.

25
00:01:59,930 --> 00:02:05,957
And these lexicon's are to map a stream
based representations of document IDs or

26
00:02:05,957 --> 00:02:09,630
terms into integer representations.

27
00:02:09,630 --> 00:02:16,549
Or, and, map back from,
integers to the screen representation.

28
00:02:17,750 --> 00:02:23,030
And the reason why we want, are interested
in using integers represent these IDs,

29
00:02:23,030 --> 00:02:26,930
is because,
integers are often easier to handle.

30
00:02:26,930 --> 00:02:29,770
For example,
integers can be used as index for

31
00:02:29,770 --> 00:02:33,240
array and they are also easy to compress.

32
00:02:34,430 --> 00:02:39,940
So this is a, one reason why we,
tend to map these streams

33
00:02:39,940 --> 00:02:46,730
into integers so that so that we don't
have to, carry these streams around.

34
00:02:46,730 --> 00:02:48,070
So how does this approach work?

35
00:02:48,070 --> 00:02:49,810
Well, it's very simple.

36
00:02:49,810 --> 00:02:53,140
We're going to scan these
documents sequentially, and

37
00:02:53,140 --> 00:02:58,260
then pause the documents and
a count the frequencies of terms.

38
00:02:58,260 --> 00:03:02,280
And in this, stage we generally sort

39
00:03:02,280 --> 00:03:07,100
the frequencies by document IDs because we
process each document that sequentially.

40
00:03:07,100 --> 00:03:11,360
So, we first encounter all the terms in,
the first document.

41
00:03:11,360 --> 00:03:16,130
Therefore, the document IDs,
are all once in this stage.

42
00:03:16,130 --> 00:03:21,115
And so, and, this would be

43
00:03:21,115 --> 00:03:25,740
followed by document IDs 2.

44
00:03:25,740 --> 00:03:29,951
And, and they're naturally sort in this
order just because we process the data in

45
00:03:29,951 --> 00:03:31,280
this order.

46
00:03:31,280 --> 00:03:34,350
At some point, the,
we will run out of memory and

47
00:03:34,350 --> 00:03:38,575
that would have to,
to write them into the disk.

48
00:03:38,575 --> 00:03:44,030
But before we do that,
we're going to a sort them, just,

49
00:03:44,030 --> 00:03:48,030
use whatever memory we have,
we can sort them, and

50
00:03:48,030 --> 00:03:51,518
then, this time,
we're going to sort based on term IDs.

51
00:03:51,518 --> 00:03:59,650
Note that here, we're using, this,
the term IDs as a key to sort.

52
00:03:59,650 --> 00:04:03,920
So, all the entries that share the same
term would be grouped together.

53
00:04:03,920 --> 00:04:09,360
In this case,
we can see all the, all the IDs

54
00:04:09,360 --> 00:04:14,090
of documents that match term
one would be grouped together.

55
00:04:14,090 --> 00:04:18,860
And we're going to write this into
the disk as a temporary file.

56
00:04:18,860 --> 00:04:24,030
And that would, allow us to use the memory
to process the next batch of documents,

57
00:04:24,030 --> 00:04:26,670
and we're going to do that for
all the documents.

58
00:04:26,670 --> 00:04:31,200
So we're going to write a lot of
temporary files into the disk.

59
00:04:32,710 --> 00:04:35,010
And then,
the next stage is to do merge sort.

60
00:04:35,010 --> 00:04:38,360
Basically, we're going to,
merge them and the sort them.

61
00:04:38,360 --> 00:04:42,320
Eventually, we will get a single
inverted index where the,

62
00:04:42,320 --> 00:04:45,300
their entries are sorted
based on term IDs.

63
00:04:46,950 --> 00:04:50,870
And on the top,
we can see these are the order entries for

64
00:04:50,870 --> 00:04:53,620
the documents that match term ID 1.

65
00:04:53,620 --> 00:04:59,600
So this is basically how we can do,
the construction of inverted index,

66
00:04:59,600 --> 00:05:05,981
even though that they're or
cannot be, or loaded into the memory.

67
00:05:05,981 --> 00:05:10,195
Now, we mentioned earlier that

68
00:05:11,245 --> 00:05:16,245
because the po, postings are very large,
it's desirable to compress them.

69
00:05:16,245 --> 00:05:20,070
So let's now talk a little bit about
how we compress inverted index.

70
00:05:21,110 --> 00:05:24,152
Well, the idea of compression, in general,

71
00:05:24,152 --> 00:05:28,310
is you leverage skewed
distributions of values.

72
00:05:28,310 --> 00:05:32,100
And we generally have to use variable
lengths in coding instead of the fixed

73
00:05:32,100 --> 00:05:38,745
lengths in coding as we', using,
by defaulting a program language like C++.

74
00:05:41,080 --> 00:05:46,050
And so, how can we leverage the skewed
distributions of values to,

75
00:05:46,050 --> 00:05:48,170
compress these values?

76
00:05:48,170 --> 00:05:54,420
Well, in general, we would use fewer
bits to encode those frequent words

77
00:05:54,420 --> 00:06:00,650
at a cost of using, longer bits from
the code than those, rare values.

78
00:06:00,650 --> 00:06:04,560
So in our case, let's think about how
we can compress the tf, term frequency.

79
00:06:05,830 --> 00:06:09,670
If you can picture what the inverted
index would look like and

80
00:06:09,670 --> 00:06:13,890
you'll see in postings there are a lot of,
term frequencies.

81
00:06:13,890 --> 00:06:18,508
Those are the frequencies of terms,
in all those documents.

82
00:06:18,508 --> 00:06:25,650
Now, we, if you think about it, what
kind of values are most frequent there?

83
00:06:25,650 --> 00:06:29,980
You probably will, be able to guess
that the small numbers tend to occur

84
00:06:29,980 --> 00:06:32,540
far more frequently than large numbers.

85
00:06:32,540 --> 00:06:33,990
Why?

86
00:06:33,990 --> 00:06:38,230
Well, think of about
the distribution of words, and

87
00:06:38,230 --> 00:06:42,760
this is due to Zipf's law and
many words occur just, rarely.

88
00:06:42,760 --> 00:06:47,095
So we see a lot of small numbers,
therefore, we can use fewer bits for

89
00:06:47,095 --> 00:06:51,845
the small, but highly frequent integers,

90
00:06:53,585 --> 00:06:57,095
and at the cost of using more bits for
large integers.

91
00:06:58,445 --> 00:06:59,865
This is a trade-off, of course.

92
00:06:59,865 --> 00:07:05,580
If the values are distributed uniformly
and this won't save us any, spacing.

93
00:07:05,580 --> 00:07:10,950
But because we tend to see many
small values, they're very frequent.

94
00:07:10,950 --> 00:07:15,190
We can save on average
even though sometimes,

95
00:07:15,190 --> 00:07:17,730
when we see a large number we
have to use a lot of bits.

96
00:07:19,740 --> 00:07:23,700
What about the document IDs
that we also saw in postings.

97
00:07:23,700 --> 00:07:27,165
Well, they are not,
distributed in a skewed way, right?

98
00:07:27,165 --> 00:07:31,860
So, how can we deal with that?

99
00:07:31,860 --> 00:07:34,616
Well, it turns out you can
use a trick called the d-gap,

100
00:07:34,616 --> 00:07:38,850
and that, that is to store
the difference of these term IDs.

101
00:07:38,850 --> 00:07:44,500
And we can, imagine if a term
has matched many documents,

102
00:07:44,500 --> 00:07:46,640
then there will be a long
list of document IDs.

103
00:07:46,640 --> 00:07:52,030
So when we take the gap, and when we take
difference between adjacent document IDs,

104
00:07:52,030 --> 00:07:54,340
those gaps will be small.

105
00:07:54,340 --> 00:07:58,090
So we'll again see a lot of small numbers,
whereas,

106
00:07:58,090 --> 00:08:02,040
if a term occurred in only a few
documents, then the gap would be large.

107
00:08:02,040 --> 00:08:06,610
The larger numbers will not be frequent,
so this creates some skewed distribution

108
00:08:06,610 --> 00:08:10,669
that would allow us to,
to compress these values.

109
00:08:11,850 --> 00:08:18,540
This is also possible because in order to
uncover or uncompress these document IDs,

110
00:08:18,540 --> 00:08:23,320
we have to sequentially process the data
because we stored the difference.

111
00:08:23,320 --> 00:08:26,410
And in order to recover the,
the exact document ID,

112
00:08:26,410 --> 00:08:30,560
we have to first recover the previous
document ID, and then, we can add

113
00:08:30,560 --> 00:08:35,830
the difference to the previous document ID
to restore the, the current document ID.

114
00:08:35,830 --> 00:08:40,603
Now, this was possible because we
only needed to have sequential

115
00:08:40,603 --> 00:08:42,900
access to those document IDs.

116
00:08:42,900 --> 00:08:46,930
Once we look up a term we fetch all
the document IDs that match the term,

117
00:08:46,930 --> 00:08:48,670
then we sequentially process them.

118
00:08:48,670 --> 00:08:52,090
So it's very natural that's why this,
trick actually works.

119
00:08:53,600 --> 00:08:55,760
And there are many different methods for
encoding.

120
00:08:55,760 --> 00:09:02,180
So binary code is a common used code in,
in just any program.

121
00:09:02,180 --> 00:09:05,904
Language that we use basically
a fixed length in coding.

122
00:09:05,904 --> 00:09:08,979
Unary code and gamma code, and
delta code are all possible in this and

123
00:09:08,979 --> 00:09:11,240
there are many other possible in this.

124
00:09:11,240 --> 00:09:14,130
So let's look at some
of them in more detail.

125
00:09:14,130 --> 00:09:16,830
Binary code is really
equal-length in coding.

126
00:09:16,830 --> 00:09:20,970
And that's a property for
the randomly distributed values.

127
00:09:20,970 --> 00:09:24,831
The unary coding is is a variable and
it's important [INAUDIBLE].

128
00:09:24,831 --> 00:09:29,346
In this case, integer that is,
I've missed one or

129
00:09:29,346 --> 00:09:33,830
we encode that as x minus 1,
1 bit followed by 0.

130
00:09:33,830 --> 00:09:39,029
So for example, 3 would be encoded
as two 1s followed by a 0,

131
00:09:39,029 --> 00:09:45,310
whereas 5 would be encoded as
four 1s followed by 0, et cetera.

132
00:09:45,310 --> 00:09:49,844
So now, now you can imagine how
many bits do we have to use for

133
00:09:49,844 --> 00:09:52,040
a large number like 100.

134
00:09:52,040 --> 00:09:57,470
So, how many bits do I have to use for
exactly for a number like 100?

135
00:09:57,470 --> 00:10:02,200
Well, exactly, we have to use 100 bits,

136
00:10:02,200 --> 00:10:07,160
but so, it's the same number of
bits as the value of this number.

137
00:10:07,160 --> 00:10:08,980
So, this is very inefficient.

138
00:10:08,980 --> 00:10:12,360
If you were likely to
see some large numbers,

139
00:10:12,360 --> 00:10:17,620
imagine if you occasionally see a number
like 1000, you have to use 1000 bits.

140
00:10:17,620 --> 00:10:21,650
So, this only works where if you
are absolutely sure that there would be no

141
00:10:21,650 --> 00:10:23,120
large numbers.

142
00:10:23,120 --> 00:10:28,600
Mostly very frequent,
they're often using very small numbers.

143
00:10:28,600 --> 00:10:30,430
Now, how do you decode this code?

144
00:10:30,430 --> 00:10:34,210
Since these are variables
lengths in coding methods, and

145
00:10:34,210 --> 00:10:37,840
you can't just count how many bits and
then just stop.

146
00:10:37,840 --> 00:10:38,500
Right?

147
00:10:38,500 --> 00:10:43,940
You can say eight bits or 32 bits,
then you, you will start another code.

148
00:10:43,940 --> 00:10:50,860
There are variable lengths, so,
you have to rely on some mechanism.

149
00:10:50,860 --> 00:10:55,250
In this case for unary, you can see
it's very easy to see the boundary.

150
00:10:55,250 --> 00:10:59,330
Now you can easily see 0 would
signal the end of encoding.

151
00:10:59,330 --> 00:11:03,259
So you just count how many 1s you
have seen, and then you hit the 0.

152
00:11:03,259 --> 00:11:07,810
You know you have finished one number,
you start another number.

153
00:11:07,810 --> 00:11:15,287
Now which is to start at unary code is to
aggressive in rewarding small numbers.

154
00:11:15,287 --> 00:11:20,430
And if you occasionally can see a very
big number, it will be a disaster.

155
00:11:20,430 --> 00:11:24,900
So what about some other
less aggressive method?

156
00:11:24,900 --> 00:11:27,500
Well, gamma coding is one of them.

157
00:11:27,500 --> 00:11:32,821
And in this method, we can do,
use unary coding for

158
00:11:32,821 --> 00:11:36,958
a transformed form of the value.

159
00:11:36,958 --> 00:11:41,190
So it's 1 plus the flow of log of x.

160
00:11:41,190 --> 00:11:47,910
So the magnitude of this value is
much lower than the original, x.

161
00:11:47,910 --> 00:11:53,140
So that's why we have four
using urinary code for that so,

162
00:11:54,220 --> 00:11:58,920
and so we, first we have the urinary
code for coding this log of s.

163
00:11:58,920 --> 00:12:02,530
And this will be followed by
a uniform code or binary code, and

164
00:12:02,530 --> 00:12:08,768
this is basically the same uniform
code and binary code are the same.

165
00:12:08,768 --> 00:12:16,120
And we're going to use this code to code
the remaining part of the value of x.

166
00:12:16,120 --> 00:12:21,815
And this is basically, precisely,
x minus 1, 2 to the flow of log of x.

167
00:12:25,042 --> 00:12:30,034
So the unary code or basically code
with a flow of log of x, well,

168
00:12:30,034 --> 00:12:32,350
I added one there, and here.

169
00:12:34,084 --> 00:12:39,072
But the remaining part will,
we using uniform

170
00:12:39,072 --> 00:12:44,756
code to actually code
the difference between the x and

171
00:12:44,756 --> 00:12:48,010
and this, 2 to the log of x.

172
00:12:49,530 --> 00:12:56,410
And, and it's easy to to show that for
this this value, there's difference.

173
00:12:56,410 --> 00:12:59,680
We only need to use up to,

174
00:13:01,120 --> 00:13:05,390
this many bits and
in flow of log of x bits.

175
00:13:06,530 --> 00:13:08,410
And this is easy to understand,

176
00:13:08,410 --> 00:13:12,910
if the difference is too large then we
would have a higher flow of log of x.

177
00:13:14,330 --> 00:13:15,440
So, here are some examples.

178
00:13:15,440 --> 00:13:19,000
For example, 3 is encoded as 101.

179
00:13:19,000 --> 00:13:21,560
The first two digits are the unary code.

180
00:13:21,560 --> 00:13:22,353
Right.

181
00:13:22,353 --> 00:13:26,320
So, this is for the value 2.

182
00:13:26,320 --> 00:13:26,969
Right.

183
00:13:26,969 --> 00:13:31,080
10 encodes 2 in unary coding.

184
00:13:32,490 --> 00:13:37,689
And so, that means log of x,
the flow of log of x is 1,

185
00:13:37,689 --> 00:13:45,620
because we will actually use unary code
to encode 1 plus the flow of log of x.

186
00:13:45,620 --> 00:13:50,050
Since this is 2, then we know that
the floor of log of x is actually 1.

187
00:13:52,100 --> 00:13:55,732
So but,
3 is still larger than 2 to the 1, so

188
00:13:55,732 --> 00:14:00,050
the difference is 1, and
that 1 is encoded here at the end.

189
00:14:01,460 --> 00:14:03,439
So that's why we have 101 for 3.

190
00:14:05,901 --> 00:14:11,504
Now, similarly 5 is encoded
as 110 followed by 01.

191
00:14:12,970 --> 00:14:18,980
And in this case,
the unary code encodes 3.

192
00:14:18,980 --> 00:14:26,590
So, this is the unary code for 110 and
so the floor of log of x is 2.

193
00:14:26,590 --> 00:14:30,875
And that means, we will compute
the difference between 5 and

194
00:14:30,875 --> 00:14:35,400
the 2 to the 2, and that's 1, and
so we now have again 1 at the end.

195
00:14:35,400 --> 00:14:40,940
But this time, we're going to
use two bits because with this

196
00:14:40,940 --> 00:14:47,230
level of flow of log of x,
we could have more numbers, 5, 6, 7.

197
00:14:47,230 --> 00:14:51,200
They would all share the same prefix here,
110.

198
00:14:51,200 --> 00:14:53,210
So, in order to differentiate them,

199
00:14:53,210 --> 00:14:57,690
we have to use two bits,
in the end to differentiate them.

200
00:14:57,690 --> 00:15:03,330
So you can imagine 6 would be, 10 here
in the end instead of 01, after 110.

201
00:15:03,330 --> 00:15:08,480
It's also true that the form
of a gamma code is always,

202
00:15:10,095 --> 00:15:15,165
the first odd number of bits,
and in the center, there was a 0.

203
00:15:15,165 --> 00:15:17,305
That's the end of the unary code.

204
00:15:18,335 --> 00:15:24,375
And before that, or to, on the left
side of this 0, there will be all 1s.

205
00:15:24,375 --> 00:15:30,225
And on the right side of this 0,
it's binary coding or uniform coding.

206
00:15:32,600 --> 00:15:36,510
So how can you decode such a code?

207
00:15:36,510 --> 00:15:40,000
Well, you again first do unary coding,
right?

208
00:15:40,000 --> 00:15:43,870
Once you hit 0,
you know you have got the unary code.

209
00:15:43,870 --> 00:15:48,546
And this also will tell you how many
bits you have to read further to

210
00:15:48,546 --> 00:15:50,431
decode the uniform code.

211
00:15:50,431 --> 00:15:53,890
So this is how you can
decode a gamma code.

212
00:15:53,890 --> 00:15:57,200
There is also delta code, but
that's basically same as gamma code,

213
00:15:57,200 --> 00:16:01,390
except that you replace the unary
prefix with the gamma code.

214
00:16:01,390 --> 00:16:04,980
So that's even less
conservative than gamma code,

215
00:16:04,980 --> 00:16:08,910
in terms of avoiding the small integers.

216
00:16:08,910 --> 00:16:12,399
So that means it's okay if you
occasionally see a large number.

217
00:16:12,399 --> 00:16:16,695
It's, it's, you know,
it's okay with delta code.

218
00:16:16,695 --> 00:16:18,274
It's also fine with gamma code.

219
00:16:18,274 --> 00:16:24,464
It's really a big loss for unary code,
and they are all operating,

220
00:16:24,464 --> 00:16:32,078
of course, at different degrees of
favoring short favoring small integers.

221
00:16:32,078 --> 00:16:38,560
And that also means they would
appropriate for sorting distribution.

222
00:16:38,560 --> 00:16:41,720
But none of them is perfect for
all distributions.

223
00:16:41,720 --> 00:16:43,370
And which method works,

224
00:16:43,370 --> 00:16:47,622
the best would have to depend on
the actual distribution in your data set.

225
00:16:47,622 --> 00:16:49,950
For inverted index, compression,

226
00:16:49,950 --> 00:16:52,840
people have found that gamma
coding seems to work well.

227
00:16:55,280 --> 00:16:58,430
So how to uncompress inverted index?

228
00:16:58,430 --> 00:16:59,900
We just, talked about this.

229
00:16:59,900 --> 00:17:02,920
Firstly, you decode those encode integers.

230
00:17:02,920 --> 00:17:07,910
And we just, I think discussed how we
decode unary coding and gamma coding.

231
00:17:09,160 --> 00:17:11,070
So I won't repeat.

232
00:17:11,070 --> 00:17:15,720
What about the document IDs that
might be compressed using d-gap?

233
00:17:15,720 --> 00:17:18,330
Well, we're going to do
sequential decoding.

234
00:17:18,330 --> 00:17:23,800
So suppose the encoded idealist is x1,
x2, x3 et cetera.

235
00:17:23,800 --> 00:17:27,720
We first decode x1 to obtain
the first document ID, ID1.

236
00:17:27,720 --> 00:17:30,540
Then, we will decode x2,

237
00:17:30,540 --> 00:17:34,610
which is actually the difference between
the second ID and the first one.

238
00:17:34,610 --> 00:17:41,330
So we have to add the decoded value
of x2 to ID1 to recover the value

239
00:17:41,330 --> 00:17:46,690
of the,
the ID at this secondary position, right.

240
00:17:46,690 --> 00:17:52,860
So this is where you can see the advantage
of, converting document IDs into integers.

241
00:17:52,860 --> 00:17:55,820
And that allows us to do this
kind of compression, and

242
00:17:55,820 --> 00:17:59,590
we just repeat until we
decode all the documents.

243
00:17:59,590 --> 00:18:04,438
Every time we use the document
ID in the previous position

244
00:18:04,438 --> 00:18:08,983
to help recover the document
ID in the next position.

245
00:18:08,983 --> 00:18:18,983
[MUSIC]

